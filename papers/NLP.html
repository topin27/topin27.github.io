<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>自然语言处理相关论文阅读笔记</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="/static/custom.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">自然语言处理相关论文阅读笔记</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#event-extraction"><span class="toc-section-number">1</span> Event Extraction</a><ul>
<li><a href="#the-stages-of-event-extraction"><span class="toc-section-number">1.1</span> The Stages of event extraction</a><ul>
<li><a href="#触发词识别"><span class="toc-section-number">1.1.1</span> 触发词识别</a></li>
<li><a href="#论元识别"><span class="toc-section-number">1.1.2</span> 论元识别</a></li>
<li><a href="#事件实体共指"><span class="toc-section-number">1.1.3</span> 事件实体共指</a></li>
</ul></li>
<li><a href="#中文事件抽取关键技术研究"><span class="toc-section-number">1.2</span> 中文事件抽取关键技术研究</a><ul>
<li><a href="#事件触发词的识别"><span class="toc-section-number">1.2.1</span> 事件触发词的识别</a></li>
<li><a href="#论元角色的识别"><span class="toc-section-number">1.2.2</span> 论元角色的识别</a></li>
</ul></li>
<li><a href="#todo-joint-event-extraction-via-recurrent-neural-networks"><span class="toc-section-number">1.3</span> TODO Joint Event Extraction via Recurrent Neural Networks</a></li>
<li><a href="#todo-joint-event-extraction-via-structured-prediction-with-global-features"><span class="toc-section-number">1.4</span> TODO Joint Event Extraction via Structured Prediction with Global Features</a></li>
<li><a href="#a-hybrid-approach-for-event-extraction"><span class="toc-section-number">1.5</span> A Hybrid Approach for Event Extraction</a></li>
<li><a href="#event-extraction-from-social-media-text-using-conditional-random-field"><span class="toc-section-number">1.6</span> Event extraction from Social Media text using Conditional Random Field</a></li>
<li><a href="#doing-joint-extraction-of-events-and-entities-within-a-document-context"><span class="toc-section-number">1.7</span> DOING Joint Extraction of Events and Entities within a Document Context</a></li>
<li><a href="#open-domain-event-extraction-from-twitter"><span class="toc-section-number">1.8</span> Open Domain Event Extraction from Twitter</a></li>
<li><a href="#event-extraction-as-dependency-parsing"><span class="toc-section-number">1.9</span> Event Extraction as Dependency Parsing</a></li>
<li><a href="#todo-nyus-chinese-ace-2005-edr-system-description"><span class="toc-section-number">1.10</span> TODO NYU’s Chinese ACE 2005 EDR System Description</a></li>
<li><a href="#todo-extracting-structured-information-from-user-queries-with-semi-supervised-conditional-random-fields"><span class="toc-section-number">1.11</span> TODO Extracting Structured Information from User Queries with Semi-Supervised Conditional Random Fields</a></li>
</ul></li>
<li><a href="#open-information-extraction"><span class="toc-section-number">2</span> Open Information Extraction</a><ul>
<li><a href="#文献"><span class="toc-section-number">2.1</span> 文献</a><ul>
<li><a href="#todo-leveraging-linguistic-structure-for-open-domain-information"><span class="toc-section-number">2.1.1</span> TODO Leveraging Linguistic Structure For Open Domain Information</a></li>
</ul></li>
</ul></li>
<li><a href="#主题提取"><span class="toc-section-number">3</span> 主题提取</a><ul>
<li><a href="#文献-1"><span class="toc-section-number">3.1</span> 文献</a><ul>
<li><a href="#todo-基于lda模型的博客主题提取."><span class="toc-section-number">3.1.1</span> TODO 基于LDA模型的博客主题提取.</a></li>
<li><a href="#todo-exploratory-analysis-of-highly-heterogeneous-document-collections."><span class="toc-section-number">3.1.2</span> TODO Exploratory analysis of highly heterogeneous document collections.</a></li>
</ul></li>
</ul></li>
<li><a href="#评论倾向与情感分析"><span class="toc-section-number">4</span> 评论倾向与情感分析</a><ul>
<li><a href="#文献-2"><span class="toc-section-number">4.1</span> 文献</a><ul>
<li><a href="#基于层次结构的多策略中文微博情感分析和特征抽取."><span class="toc-section-number">4.1.1</span> 基于层次结构的多策略中文微博情感分析和特征抽取.</a></li>
</ul></li>
<li><a href="#数据集"><span class="toc-section-number">4.2</span> 数据集</a><ul>
<li><a href="#movie-review-data"><span class="toc-section-number">4.2.1</span> Movie Review Data</a></li>
</ul></li>
</ul></li>
<li><a href="#垃圾邮件识别"><span class="toc-section-number">5</span> 垃圾邮件识别</a><ul>
<li><a href="#数据集-1"><span class="toc-section-number">5.1</span> 数据集</a><ul>
<li><a href="#spambase"><span class="toc-section-number">5.1.1</span> SpamBase</a></li>
<li><a href="#enron"><span class="toc-section-number">5.1.2</span> Enron</a></li>
</ul></li>
</ul></li>
<li><a href="#文本相似度"><span class="toc-section-number">6</span> 文本相似度</a><ul>
<li><a href="#文献-3"><span class="toc-section-number">6.1</span> 文献</a><ul>
<li><a href="#基于语义理解的文本相似度算法.-金博-史彦军-滕弘飞"><span class="toc-section-number">6.1.1</span> 基于语义理解的文本相似度算法. (金博, 史彦军, 滕弘飞)</a></li>
<li><a href="#todo-基于属性论的文本相似度计算.-潘谦红-王炬-史忠植"><span class="toc-section-number">6.1.2</span> TODO 基于属性论的文本相似度计算. (潘谦红, 王炬, 史忠植)</a></li>
</ul></li>
</ul></li>
<li><a href="#文本匹配"><span class="toc-section-number">7</span> 文本匹配</a><ul>
<li><a href="#文献-4"><span class="toc-section-number">7.1</span> 文献</a><ul>
<li><a href="#done-深度文本匹配综述.-庞亮-兰艳艳-徐君"><span class="toc-section-number">7.1.1</span> DONE 深度文本匹配综述. (庞亮, 兰艳艳, 徐君)</a></li>
<li><a href="#todo-a-deep-architecture-for-semantic-matching-with-multiple"><span class="toc-section-number">7.1.2</span> TODO A deep architecture for semantic matching with multiple</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
<h1 id="event-extraction"><span class="header-section-number">1</span> Event Extraction</h1>
<h2 id="the-stages-of-event-extraction"><span class="header-section-number">1.1</span> The Stages of event extraction</h2>
<p><small>David Ahn | 2005 | <a href="http://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/W06-0901.pdf">论文</a></small></p>
<p>基本上可以算是事件抽取的入门论文了，论文中使用的方法是典型的 Pipeline 式的事件抽取方法，整个模型分成了四个子模型分别检测：</p>
<ol type="1">
<li>触发词识别</li>
<li>论元识别</li>
<li>属性识别（识别极性等）</li>
<li>事件共指等</li>
</ol>
<h3 id="触发词识别"><span class="header-section-number">1.1.1</span> 触发词识别</h3>
<p>对于触发词识别模型，又分为了两个子模型，第一个模型用于判断文章中的某个词是否是触发词，二个模型用于判断该触发词属于哪一类事件。</p>
<p>特征方面，从以下角度提取特征：</p>
<ul>
<li>词性特征</li>
<li>WordNet 特征</li>
<li>前面3个词的词性</li>
<li>后面3个词的词性</li>
<li>句法依存特征</li>
<li>相关的实体特征</li>
</ul>
<h3 id="论元识别"><span class="header-section-number">1.1.2</span> 论元识别</h3>
<p>使用的特征</p>
<ul>
<li>Anchor Word of event mention.</li>
<li>Event type fo event mention</li>
<li>Constituent head word of entity mention: full, lowercase, POS tag, and depth in parse tree.</li>
<li>Determiner of entity mention, if any</li>
<li>Entity type and mention type of entity mention</li>
<li>Dependency path between anchor word and constituent head word of entity mention, expressed as a sequence of labels, of words, and of POS tags.</li>
</ul>
<h3 id="事件实体共指"><span class="header-section-number">1.1.3</span> 事件实体共指</h3>
<blockquote>
<p>Uses a mention-pair coreference model with probabilistic decoding. Each event mention in a document is paired with every other event mention, and a classifier assigns to each pair of mentions the probability that the paired mentions corefer.</p>
</blockquote>
<h2 id="中文事件抽取关键技术研究"><span class="header-section-number">1.2</span> 中文事件抽取关键技术研究</h2>
<p><small>谭红叶 | 2013 | 哈工大 </small></p>
<p>哈工大的毕业论文，数据集使用的是 ACE2005 语料集。</p>
<h3 id="事件触发词的识别"><span class="header-section-number">1.2.1</span> 事件触发词的识别</h3>
<p>论文中和事件抽取相关的部分应该是典型的 Pipeline 方法,基于这样的一个思想:事件的检测就是判断一个句子是否是一个事件句,如果是事件句,再以一定的特征判定其属于哪个类别,从而完成事件的检测与分类任务。完成事件句的确定及检测分类后，在对事件句中的事件触发词进行识别，避免非事件句进行的干扰。</p>
<p>至于判定事件句事件类型所用到的特征，其实就是训练语料中所有句子的词，经过特征选择之后留下的特征。而在触发词的识别过程中，主要使用了一个二分类模型来对触发词进行判定，该过程用到的特征有：</p>
<ul>
<li>前一词的词形特征和词性特征</li>
<li>后一词的词形特征和词性特征</li>
<li>当前词的词形特征和词性特征</li>
<li>依存特征</li>
</ul>
<p>同时考虑到 ACE2005 的语料较小，容易产生特征稀疏的问题，因此还引入了以下特征：</p>
<ul>
<li>词林特征：主要是《同义词词林》中的义类代码</li>
<li>知网特征：当前词在 HowNet 中定义的义元解释</li>
</ul>
<h3 id="论元角色的识别"><span class="header-section-number">1.2.2</span> 论元角色的识别</h3>
<p><strong>定义：</strong> 事件的参与者即为论元，此外与事件紧密相关的一些属性也属于事件论元。</p>
<p>在该论文中，对于论元角色的识别时使用了一个“多层级模式”匹配的方法，具体来说，论文设计了四个层级的模式：</p>
<ol type="1">
<li>第一级模式：基于词的硬模式，从词一级反映触发词与论元角色之间的关系，形如<code>EventType WordLeft TRIGGER WordBetween ETVType WordRight -&gt; ROLE</code></li>
<li>第二级模式：基于依存路径的硬模式，形如<code>EventType TRIGGER ETVType DependencyPath -&gt; ROLE</code></li>
<li>第三级模式：是第一级模式的泛化，其中分为软匹配部分和硬匹配部分，由精确匹配变成了模糊匹配，形如<code>EventType TRIGGER ETVType [WordLeft] [WordBetween] [WordRight] -&gt; ROLE</code></li>
<li>第四级模式：类似于第三级模式，形如<code>EventType TRIGGERType ETVType [WordLeft] [WordBetween] [WordRight] -&gt; ROLE</code></li>
</ol>
<p>其中第一级和第二级模式需要精确匹配，第三四级模式通过计算可信度来衡量模式的匹配度。这种多层级的方式虽然有一定的效果，但是相关的性能并不是很好，因此使用了 CRF 相关模型进行了改进。</p>
<p>由于担当论元角色的是实体、时间和数值，因此将论元角色识别看作是一个实体、时间和数值的多分类问题。为每一个类别建立一个多类分类器。使用如下的特征：</p>
<ul>
<li>触发词特征：词性、词形</li>
<li>事件类型：触发词所表示的事件类型</li>
<li>当前实体特征：实体类别、人名以外的实体的中心词</li>
<li>实体的前一词的词形特征和词性特征</li>
<li>实体的后一词的词性、词形</li>
<li>触发词的前一次的词性、词形</li>
<li>触发词后一词的词性、词形</li>
<li>依存路径特征：触发词和当前实体之间的依存路径，具体值为触发词和当前实体之间的依存关系所组成的字符串</li>
<li>模式相似度特征：前面所述的第三级和第四级模式的相似度。</li>
</ul>
<h2 id="todo-joint-event-extraction-via-recurrent-neural-networks"><span class="header-section-number">1.3</span> TODO Joint Event Extraction via Recurrent Neural Networks</h2>
<p><small>Thien Huu Nguyen | 纽约大学 | 2016 | <a href="https://cs.nyu.edu/~thien/pubs/jointEE.pdf">论文</a> | <a href="https://github.com/anoperson/jointEE-NN">代码</a></small></p>
<h2 id="todo-joint-event-extraction-via-structured-prediction-with-global-features"><span class="header-section-number">1.4</span> TODO Joint Event Extraction via Structured Prediction with Global Features</h2>
<p><small>Qi Li | 纽约城市大学 | <a href="http://web.engr.oregonstate.edu/~huanlian/papers/jointIE.pdf">论文</a></small></p>
<h2 id="a-hybrid-approach-for-event-extraction"><span class="header-section-number">1.5</span> A Hybrid Approach for Event Extraction</h2>
<p><small> Anup Kumar Kolya | 2010 | <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.458.2356&amp;rep=rep1&amp;type=pdf">论文</a></small></p>
<p>首先使用了 CRF 模型进行了事件抽取训练，但是由于训练出的模型抽取 <code>deverbial</code> 类实体时效果不好，而引入了特定策略进行改进，这些策略基于语义角色标注、WordNet和手工规则。</p>
<p>最终效果能达到 <code>precision=93%, recall=96%, F-measure=94.47</code> ？</p>
<p>基于 CRF 的模型所用的特征包括：</p>
<ul>
<li>POS tag of event terms</li>
<li>Event Tense: This feature is useful to capture the standard distinctions among the grammatical categories of verbal phrases. The tense attribute can have values, PRESENT, PAST, FUTURE, INFINITIVE, PRESPART, PASTPART, or NONE.</li>
<li>Event Aspect: denotes the aspect of the events. The aspect attribute may take values, PROGRESSIVE, PERFECTIVE and PERFECTIVE PROGRESSIVE or NONE.</li>
<li>Event Polarity.</li>
<li>Event Modality: The modality attribute is only present if there is a modal word that modifies the instance.</li>
<li>Event Class</li>
</ul>
<p>使用语义角色标注进行改进事件抽取方面，目前是直接使用谓语作为事件触发词，通过语义角色标注可以得到该词的所有附属词。</p>
<p>论文基于语料集 TempEval-2010 进行试验。</p>
<h2 id="event-extraction-from-social-media-text-using-conditional-random-field"><span class="header-section-number">1.6</span> Event extraction from Social Media text using Conditional Random Field</h2>
<p><small> Nagesh Bhattu Sristy | <a href="http://ceur-ws.org/Vol-2036/T5-3.pdf">论文</a></small></p>
<p>酸爽，针对印度语的事件提取，整体没有太多的创新点。其总体方式是：</p>
<pre><code>Tweets -&gt; Tokenizer -&gt; Feature Extraction -&gt; POS Tagging -&gt; Event Detection -&gt; CRF based Event Extraction</code></pre>
<p>其中<code>Event Detection</code>步骤是使用一个分类模型进行检测。<code>Event Extraction</code>部分中对每一个 token (<span class="math inline">\(x_i\)</span>) 都进行了特征设计，然后预测其<span class="math inline">\(y_i\)</span>。</p>
<h2 id="doing-joint-extraction-of-events-and-entities-within-a-document-context"><span class="header-section-number">1.7</span> DOING Joint Extraction of Events and Entities within a Document Context</h2>
<p><small> Yang B, Mitchell T M | 卡梅隆大学 | <a href="https://arxiv.org/pdf/1609.03632.pdf">论文</a> | <a href="https://resources.sei.cmu.edu/asset_files/Presentation/2017_017_001_506498.pdf">PPT</a> | <a href="https://github.com/bishanyang/EventEntityExtractor">代码</a></small></p>
<p>论文将事件抽取分成了三个子过程：Learning events structures, Learning event-event relations and Learning for entity extraction. 最后使用一个模型框架将三个模型集成起来。</p>
<h2 id="open-domain-event-extraction-from-twitter"><span class="header-section-number">1.8</span> Open Domain Event Extraction from Twitter</h2>
<p><small> Ritter A , Mausam N V , Etzioni O | 华盛顿大学 | 2012 | <a href="https://dl.acm.org/citation.cfm?id=2339704">论文</a></small></p>
<p>抽取事件四元组：实体、事件短语、时间和事件类型。</p>
<p>整体大致流程是首先进行 POS Tagging，然后进行命名实体和事件短语的抽取，对事件类型进行分类，最后根据一定数量的推特中共现的实体和日期进行关联关系计算，进一步确定重要性事件。</p>
<p>分词部分由于推文内容的不规则，使用斯坦福的实体提取工具从新在推文语料上进行了训练得到优化后的分词器。在事件触发词识别方面，使用线性链条件随机场结合上下文环境、字典等特征进行训练。时间共指消解使用了 TempEx 进行解决。事件类型分类方面，利用大量未标注的语料结合 latent variable models on modeling selectional preferences 进行事件分类。</p>
<blockquote>
<p>Each event indicator phrase in our data, <span class="math inline">\(e\)</span>, is modeled as a mixture of types. For exampel the event phrase “cheered” might appear as part fo either a POLITICALEVENT, or a SPORTSEVENT. Each type corresponds to a distribution over named entities <span class="math inline">\(n\)</span> involved in specific instances of the type, in addition to a distribution over dates <span class="math inline">\(d\)</span> on which events of the type occur. Including calendar dates in our model has the effect of encouraging (though not requiring) events which occur on the same date to be assigned the same type. This is helpful in guiding inference, because distinct references to the same event should also have the same type.</p>
</blockquote>
<h2 id="event-extraction-as-dependency-parsing"><span class="header-section-number">1.9</span> Event Extraction as Dependency Parsing</h2>
<p><small> Mcclosky D, Surdeanu M, Manning C D | 斯坦福大学 | 2011 | <a href="https://nlp.stanford.edu/pubs/dmcc-acl-2011.pdf">论文</a></small></p>
<p>主要思想是将事件抽取问题简化为依存句法分析问题，依存句法分析主要使用 MSTParser。</p>
<p>系统由三部分组成：1) anchor detection, 2) 通过分析事件触发词和实体之间的结构生成可能的事件候选结构，3) 对候选结构进行重新排序选择最佳事件结构。</p>
<p>Anchor detection 借鉴了实体识别的方式对每个词所属的类型进行了分类，分类算法使用的是逻辑回归，特征方面使用了“Token-Level”、“Surface Context”、“Syntactic Context”和“Bag-of-word”四个层级的特征。</p>
<blockquote>
<p>Our approach converts the original event representation to dependency trees containing both event anchors and entity mentions, and trains a battery of parsers to recognize these structures. The trees are built using event anchors predicted by a separate classifier.</p>
</blockquote>
<p>将句子根据语义标签转换成一个图，方式如下：对于每一个 event anchor，创建边连接其对应的 arguments labeled with the slot name of the argument。然后对于那些和事件不关联的实体，从 ROOT 节点连接一条名为 ROOT-LABEL 的边指向它，最后，从 ROOT 节点连接每一个顶层的 event anchor。最终会生成一个有向图，为了生成一个树，采用了一些 post-process 的方式进行剪枝（？）</p>
<p>解析出 anchor 和相关的实体后，生成了一个 labeled dependency links between them。然后使用<code>MSTParser</code>对图进行解析，<code>MSTParser</code>可以解析出图中的最大权重树（且遍历所有节点）。</p>
<p>第三步，会在前一步解析出的一些最大权重树上，利用一些全局信息进行重新排序。</p>
<h2 id="todo-nyus-chinese-ace-2005-edr-system-description"><span class="header-section-number">1.10</span> TODO NYU’s Chinese ACE 2005 EDR System Description</h2>
<p><small> Heng Ji | 纽约大学 | <a href="https://nlp.cs.nyu.edu/pubs/papers/ACE05-NYUChinese.pdf">论文</a></small></p>
<h2 id="todo-extracting-structured-information-from-user-queries-with-semi-supervised-conditional-random-fields"><span class="header-section-number">1.11</span> TODO Extracting Structured Information from User Queries with Semi-Supervised Conditional Random Fields</h2>
<p><small> Xiao Li | 微软研究院 | <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2009/07/fp275-li.pdf">论文</a> </small></p>
<h1 id="open-information-extraction"><span class="header-section-number">2</span> Open Information Extraction</h1>
<h2 id="文献"><span class="header-section-number">2.1</span> 文献</h2>
<h3 id="todo-leveraging-linguistic-structure-for-open-domain-information"><span class="header-section-number">2.1.1</span> TODO Leveraging Linguistic Structure For Open Domain Information</h3>
<p>Extraction. (Gabor Angeli, Melvin Johnson Premkumar, and Christopher D. Manning)</p>
<p>corenlp中 <a href="https://nlp.stanford.edu/software/openie.html">OpenIE</a> 模块根据该论文实现，论文地址：<a href="https://nlp.stanford.edu/pubs/2015angeli-openie.pdf">link</a></p>
<h1 id="主题提取"><span class="header-section-number">3</span> 主题提取</h1>
<h2 id="文献-1"><span class="header-section-number">3.1</span> 文献</h2>
<h3 id="todo-基于lda模型的博客主题提取."><span class="header-section-number">3.1.1</span> TODO 基于LDA模型的博客主题提取.</h3>
<p>(王珍)</p>
<p>北大的一篇关于主题提取的硕士毕业论文。大致内容如标题所述。</p>
<h3 id="todo-exploratory-analysis-of-highly-heterogeneous-document-collections."><span class="header-section-number">3.1.2</span> TODO Exploratory analysis of highly heterogeneous document collections.</h3>
<p>(Maiya A S, Thompson J P, Loaizalemos F, et al)</p>
<h1 id="评论倾向与情感分析"><span class="header-section-number">4</span> 评论倾向与情感分析</h1>
<h2 id="文献-2"><span class="header-section-number">4.1</span> 文献</h2>
<h3 id="基于层次结构的多策略中文微博情感分析和特征抽取."><span class="header-section-number">4.1.1</span> 基于层次结构的多策略中文微博情感分析和特征抽取.</h3>
<p>(谢丽星，周明，孙茂松)</p>
<ol type="1">
<li><p>相关工作</p>
<ul>
<li>主题无关的情感分析
<ul>
<li>基于词典的方法。需要构建情感词典，然后统计文本中情感词的正负差值进行情感判定。无法解决未登录词的问题。</li>
<li>有监督的学习方法。</li>
<li>无监督的学习方法。选定基本的情感词，然后制定模板来提取短语，计算这些短语与基本情感词之间的关联度，根据正负向关联度的差值来确定情感极性。</li>
</ul></li>
<li>主题相关的情感分析
<ul>
<li>基于规则的方法。对形容词、动词、名词制定一系列规则来判定文本的极性。</li>
<li>基于特征的方法。不仅要确定情感属性，还需要确定每个情感属性涉及的产品。</li>
</ul></li>
</ul></li>
<li><p>算法设计</p>
<ul>
<li>基于表情符号的方法。统计正负情感表情符号的个数，根据个数差值来确定极性。</li>
<li>基于情感词典的规则方法。统计正负情感词的个数，根据个数差值来确定极性。</li>
<li>基于层次结构的多策略分析方法。
<ul>
<li>对文本不分句，将一条微博作为一个整体：
<ul>
<li>一步三分类：使用SVM直接进行正中负三分类；</li>
<li>二步分类：先建立模型对微博的主、客观情况进行分类，然后在此基础上提取极性特征，进一步在分为正负情感倾向。</li>
</ul></li>
<li>分句，将一条微博拆分成若干个句子，对每个句子进行分类：
<ul>
<li>句子组成规则分类：对每句进行情感分类，然后统计所有句子的情感句差值。</li>
<li>句子组成SVM分类：对每句进行情感分类，然后训练SVM分类器进行最终情感分类。</li>
</ul></li>
</ul></li>
</ul></li>
</ol>
<h2 id="数据集"><span class="header-section-number">4.2</span> 数据集</h2>
<h3 id="movie-review-data"><span class="header-section-number">4.2.1</span> Movie Review Data</h3>
<p>下载地址：https://www.cs.cornell.edu/people/pabo/movie-review-data/ ，包含1000条正面评论和1000条负面评论，广泛应用于文本分类尤其是恶意评论识别方面。</p>
<h1 id="垃圾邮件识别"><span class="header-section-number">5</span> 垃圾邮件识别</h1>
<h2 id="数据集-1"><span class="header-section-number">5.1</span> 数据集</h2>
<h3 id="spambase"><span class="header-section-number">5.1.1</span> SpamBase</h3>
<p>下载地址：https://archive.ics.uci.edu/ml/datasets/Spambase ，不是原始的邮件数据，而是已经特征化的数据，对应的特征是统计的关键字以及特殊符号。</p>
<h3 id="enron"><span class="header-section-number">5.1.2</span> Enron</h3>
<p>下载地址：https://www.cs.cmu.edu/~./enron/ ，真实环境下的真实邮件，由人工标注。用于垃圾邮件识别。Kaggle上也有这个数据集的 <a href="https://www.kaggle.com/wcukierski/enron-email-dataset">下载</a>。</p>
<h1 id="文本相似度"><span class="header-section-number">6</span> 文本相似度</h1>
<h2 id="文献-3"><span class="header-section-number">6.1</span> 文献</h2>
<h3 id="基于语义理解的文本相似度算法.-金博-史彦军-滕弘飞"><span class="header-section-number">6.1.1</span> 基于语义理解的文本相似度算法. (金博, 史彦军, 滕弘飞)</h3>
<p>在词语层次中，相似度用于衡量文本中词语的可替换程度，这里的词语相似度不等同于词语的相关度，例如“军人”和“武器”两个词，其相似度非常低，但相关度却非常高。可以这样认为，词语相似度反映的是词语之间的聚合特点，而词语相关度反映的是词语之间的组合特点。</p>
<p>论文中的文本相似度的计算方法为，首先通过语义分析计算词语相似度，接着通过分词及对句子结构进行分析计算句子相似，最后按照句子与段落之间的关系得到段落相似度的计算方法。</p>
<ol type="1">
<li><p>词语相似度</p>
<p>使用知网中的义项概念来进行：假设两个词语 <span class="math inline">\(w_1\)</span> 和 <span class="math inline">\(w_2\)</span> ，如果 <span class="math inline">\(w_1\)</span> 上有 n 个义项 <span class="math inline">\(s_{11},s_{12},…,s_{1n}\)</span> ， <span class="math inline">\(w_2\)</span> 上有 m 个义项 <span class="math inline">\(s_{21},s_{22},…,s{2m}\)</span> ，则 <span class="math inline">\(w_{1}\)</span> 与 <span class="math inline">\(w_{2}\)</span> 之间的相似度定义为各个义项的相似度的最大值： <span class="math inline">\(sim W(w_1,w_2)=max_{i=1,...,n,j=1,...,m}sim WS(s_{1i},s_{2j})\)</span> 其中 <span class="math inline">\(sim WS(s_{1},s_{2})\)</span> 表示的是两个义项的相似度，而义项都是由义原表示，因此义项相似度转换为义原相似度的计算，根据某篇文献的公式，该轮为将义原相似度定义为： <span class="math inline">\(sim WP(p_1,p_2)=\frac{\alpha}{d+\alpha}\)</span> 其中d是 <span class="math inline">\(p_{1}\)</span> 和 <span class="math inline">\(p_{2}\)</span> 在义原层次体系中的路径长度， <span class="math inline">\(*α*\)</span> 是一个可调节的参数，其含义是相似度为0.5时的路径长度，论文中取 <span class="math inline">\(\alpha=1.6\)</span></p>
<p>考虑到汉语中实词才是表达文章意义的关键词汇，在相似度计算时忽略了虚词部分的相似度计算。然后将词的义原分为第一独立义原、其他独立义原、关系义原、符号义原分别计算相似度。最终两个义项语义表达式的整体相似度为： <span class="math inline">\(sim WS(s_1,s_2)=\sum_1^4\beta_i sim WP_i(p_1,p_2)\)</span></p></li>
<li><p>句子相似度</p>
<p>将句子中的词语根据词性进行分类（名词、动词、形容词、数词、量词），然后按照分类对两句话中的词语进行词语相似度计算，取出最大的相似度作为句子的相似度。</p></li>
<li><p>段落相似度</p>
<p>同句子相似度集成词语相似度的方式一致，段落相似度也以同样的方式集成句子相似度。</p></li>
</ol>
<h3 id="todo-基于属性论的文本相似度计算.-潘谦红-王炬-史忠植"><span class="header-section-number">6.1.2</span> TODO 基于属性论的文本相似度计算. (潘谦红, 王炬, 史忠植)</h3>
<h1 id="文本匹配"><span class="header-section-number">7</span> 文本匹配</h1>
<h2 id="文献-4"><span class="header-section-number">7.1</span> 文献</h2>
<h3 id="done-深度文本匹配综述.-庞亮-兰艳艳-徐君"><span class="header-section-number">7.1.1</span> DONE 深度文本匹配综述. (庞亮, 兰艳艳, 徐君)</h3>
<p>其中一个作者的一个简述PPT：<a href="http://www.bigdatalab.ac.cn/~junxu/publications/CCIR2016-tutorial.pdf">link</a></p>
<ol type="1">
<li><p>引言</p>
<p>深度文本匹配模型划分为3类：</p>
<ul>
<li>基于单语义文档表达的深度学习模型</li>
<li>基于多语义文档表达的深度学习模型</li>
<li>直接建模匹配模式的深度学习模型</li>
</ul></li>
<li><p>文本匹配问题简介</p>
<p>衡量一个排序结果优劣的评价指标有：P@k(Precision at k), R@k(Recall at k), MAP(Mean Average Precision), MRR(Mean Reciprocal Rank)以及nDCG(normalized Discounted Cumulative Gain).</p>
<p>定义真实排序前k个文本中，匹配文本的数量是 <span class="math inline">\(G_{k}\)</span> ，而在预测排序中前k个文本中，匹配文本的数量是 <span class="math inline">\(Y_{k}\)</span> ，评价指标P@k和R<span class="citation" data-cites="k的定义如下">@k的定义如下</span>：[P@k=,R@k=]假设预测排序中的真实匹配的文本的排序位置为 <span class="math inline">\(k_{1},k_{2},…,k_{r}\)</span> ，其中r是整个列表中所有匹配文本的数量，那么指标MAP的定义如下：[MAP=]如果只考虑排名最靠前的真实匹配的文本 <span class="math inline">\(k_{1}\)</span> ，就可以到处指标MRR的定义： <span class="math inline">\(MRR=P@k_1\)</span></p></li>
<li><p>基于单语义文档表达的深度学习模型</p>
<p>广义的说，传统方法得到的只基于一个文档的特征就可以看作是一个文档的表达，比如文档中的词频，文档的长度等。而基于单语义深度学习模型中的文档表达这是利用深度学习方法生成一个文档的高维稠密向量，得到向量之后，直接计算两个向量的相似度便可输出两个文档的匹配度。</p></li>
<li><p>基于多语义文档表达的深度学习模型</p>
<p>综合考虑文本的局部性表达（词、短语等）和全局性表达（句子）。这类模型不仅会考虑两端文本最终的表达向量的相似度，也会生成局部的短语或者更长的短语的表达进行匹配。这样多粒度的匹配可以很好的补充基于单语义文档表达的深度学习模型在压缩整个句子过程中的信息损失。</p>
<ol type="1">
<li><p>多粒度卷积神经网络</p>
<p>使用卷积网络来分别得到词、短语和句子等几个不同层面的文本表达，然后将这些向量拼接到一起或者建模这些向量的相似度来得到最终的匹配值。</p>
<p>首先将一个句子拆解成4个层次，单次级别、短语级别、长短语级别和句子级别，之后将两个句子不同级别的特征进行两两的相似度计算，得到相似度矩阵，进行动态最大值池化得到两个句子的相似度得分。</p></li>
</ol></li>
</ol>
<h3 id="todo-a-deep-architecture-for-semantic-matching-with-multiple"><span class="header-section-number">7.1.2</span> TODO A deep architecture for semantic matching with multiple</h3>
<p>positional sentence representations. (Wan S, Lan Y, Guo J, et al)</p>
<ol type="1">
<li><p>Introduction</p>
<p>A lot of deep models follow the paradigm to first represent the whole sentence to a single distributed representation, and then compute similarities between the two vectors to output the mathing score. Examples include DSSM, CDSSM, ARC-I, CNTN and LSTM-RNN. The main disadvantage lies in that important local information is lost when compressing such a complicated sentence into a single vector. som other owrks focus on taking multiple granularity, e.g. word, phrase, and sentence level representations, into consideration for the matching process. Examples include ARC-II, RAE, Deep-Match, Bi-CNN-MI and MultiGranCNN, but are still far from completely solving the matching problem. Because they are limited to well capture the contextualized local information, by directly involving word and phrase level representations.</p></li>
<li><p>Our Approach</p>
<p>Firstly, each positional sentence representation is a sentence representation at one position, generated by a bidirectional long short term memory(Bi-LSTM); Secondly, the interactions between different positional sentence representations form a similarity matrix/tensor by different similarity functions; Lastly, the final matching score is produced by aggregating such interactions through k-Max pooling and a multilayer perceptron.</p></li>
</ol>
</body>
</html>

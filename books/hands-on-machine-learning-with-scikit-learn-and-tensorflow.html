<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Notes about “Hands-on Machine Learning with Scikit-learn &amp; Tensorflow”</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style>
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="/static/custom.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Notes about “Hands-on Machine Learning with Scikit-learn &amp; Tensorflow”</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#end-to-end-machine-learning-project"><span class="toc-section-number">1</span> End-to-End Machine Learning Project</a><ul>
<li><a href="#frame-the-problem-and-look-at-the-picture"><span class="toc-section-number">1.1</span> Frame the problem and look at the picture</a><ul>
<li><a href="#确定问题"><span class="toc-section-number">1.1.1</span> 确定问题</a></li>
<li><a href="#选择性能指标"><span class="toc-section-number">1.1.2</span> 选择性能指标</a></li>
<li><a href="#检验假设"><span class="toc-section-number">1.1.3</span> 检验假设</a></li>
</ul></li>
<li><a href="#get-the-data"><span class="toc-section-number">1.2</span> Get the Data</a><ul>
<li><a href="#大概的观察数据"><span class="toc-section-number">1.2.1</span> 大概的观察数据</a></li>
<li><a href="#创建测试集"><span class="toc-section-number">1.2.2</span> 创建测试集</a></li>
</ul></li>
<li><a href="#discover-and-visualize-the-data-to-gain-insights"><span class="toc-section-number">1.3</span> Discover and Visualize the Data to Gain Insights</a><ul>
<li><a href="#观察数据属性之间的关系"><span class="toc-section-number">1.3.1</span> 观察数据属性之间的关系</a></li>
<li><a href="#尝试对一部分属性进行组合"><span class="toc-section-number">1.3.2</span> 尝试对一部分属性进行组合</a></li>
</ul></li>
<li><a href="#prepare-the-data-for-machine-learning-algorithms"><span class="toc-section-number">1.4</span> Prepare the Data for Machine Learning Algorithms</a></li>
<li><a href="#select-and-train-a-model"><span class="toc-section-number">1.5</span> Select and Train a Model</a></li>
<li><a href="#fine-tune-your-model"><span class="toc-section-number">1.6</span> Fine-Tune Your Model</a></li>
</ul></li>
<li><a href="#classification"><span class="toc-section-number">2</span> Classification</a><ul>
<li><a href="#性能评价指标"><span class="toc-section-number">2.1</span> 性能评价指标</a></li>
</ul></li>
<li><a href="#training-models"><span class="toc-section-number">3</span> Training Models</a><ul>
<li><a href="#梯度下降"><span class="toc-section-number">3.1</span> 梯度下降</a></li>
<li><a href="#polynomial-regression"><span class="toc-section-number">3.2</span> Polynomial Regression</a><ul>
<li><a href="#学习曲线learning-curve"><span class="toc-section-number">3.2.1</span> 学习曲线（Learning Curve）</a></li>
</ul></li>
<li><a href="#对线性模型进行正则化"><span class="toc-section-number">3.3</span> 对线性模型进行正则化</a><ul>
<li><a href="#ridge-regression"><span class="toc-section-number">3.3.1</span> Ridge Regression</a></li>
<li><a href="#lasso-regression"><span class="toc-section-number">3.3.2</span> Lasso Regression</a></li>
<li><a href="#early-stopping"><span class="toc-section-number">3.3.3</span> Early Stopping</a></li>
<li><a href="#elastic-net"><span class="toc-section-number">3.3.4</span> Elastic Net</a></li>
</ul></li>
<li><a href="#逻辑回归"><span class="toc-section-number">3.4</span> 逻辑回归</a><ul>
<li><a href="#损失函数"><span class="toc-section-number">3.4.1</span> 损失函数</a></li>
</ul></li>
<li><a href="#softmax-regression"><span class="toc-section-number">3.5</span> Softmax Regression</a></li>
</ul></li>
<li><a href="#support-vector-machines-svm"><span class="toc-section-number">4</span> Support Vector Machines (SVM)</a><ul>
<li><a href="#soft-margin-classification"><span class="toc-section-number">4.1</span> Soft Margin Classification</a></li>
<li><a href="#非线性-svm"><span class="toc-section-number">4.2</span> 非线性 SVM</a><ul>
<li><a href="#polynomial-kernel"><span class="toc-section-number">4.2.1</span> Polynomial Kernel</a></li>
<li><a href="#adding-similarity-features"><span class="toc-section-number">4.2.2</span> Adding Similarity Features</a></li>
<li><a href="#gaussian-rbf-kernel"><span class="toc-section-number">4.2.3</span> Gaussian RBF Kernel</a></li>
</ul></li>
<li><a href="#svm-回归"><span class="toc-section-number">4.3</span> SVM 回归</a></li>
<li><a href="#under-the-hood"><span class="toc-section-number">4.4</span> Under the Hood</a><ul>
<li><a href="#训练目标"><span class="toc-section-number">4.4.1</span> 训练目标</a></li>
<li><a href="#quadratic-programming"><span class="toc-section-number">4.4.2</span> Quadratic Programming</a></li>
<li><a href="#对偶问题"><span class="toc-section-number">4.4.3</span> 对偶问题</a></li>
<li><a href="#kernelized-svm"><span class="toc-section-number">4.4.4</span> Kernelized SVM</a></li>
<li><a href="#online-svms"><span class="toc-section-number">4.4.5</span> Online SVMs</a></li>
</ul></li>
</ul></li>
<li><a href="#decision-tree"><span class="toc-section-number">5</span> Decision Tree</a><ul>
<li><a href="#训练算法"><span class="toc-section-number">5.1</span> 训练算法</a><ul>
<li><a href="#cart-classification-and-regression-tree"><span class="toc-section-number">5.1.1</span> CART (Classification And Regression Tree)</a></li>
<li><a href="#pros.-and-cons."><span class="toc-section-number">5.1.2</span> Pros. and Cons.</a></li>
</ul></li>
</ul></li>
<li><a href="#ensemble-learning-and-random-forests"><span class="toc-section-number">6</span> Ensemble Learning and Random Forests</a><ul>
<li><a href="#ensemble-时投票的方式"><span class="toc-section-number">6.1</span> Ensemble 时投票的方式</a></li>
<li><a href="#集成学习的理论基础"><span class="toc-section-number">6.2</span> 集成学习的理论基础</a></li>
<li><a href="#bagging-and-pasting"><span class="toc-section-number">6.3</span> Bagging and Pasting</a><ul>
<li><a href="#out-of-bagoob-evaluation"><span class="toc-section-number">6.3.1</span> Out-of-Bag(oob) Evaluation</a></li>
<li><a href="#random-patches-and-random-subspaces"><span class="toc-section-number">6.3.2</span> Random Patches and Random Subspaces</a></li>
<li><a href="#random-forests"><span class="toc-section-number">6.3.3</span> Random Forests</a></li>
</ul></li>
<li><a href="#boosting"><span class="toc-section-number">6.4</span> Boosting</a><ul>
<li><a href="#adaboost"><span class="toc-section-number">6.4.1</span> AdaBoost</a></li>
<li><a href="#gradient-boosting"><span class="toc-section-number">6.4.2</span> Gradient Boosting</a></li>
</ul></li>
<li><a href="#stacking"><span class="toc-section-number">6.5</span> Stacking</a></li>
</ul></li>
<li><a href="#dimensionality-reduction"><span class="toc-section-number">7</span> Dimensionality Reduction</a><ul>
<li><a href="#常见的降维方式"><span class="toc-section-number">7.1</span> 常见的降维方式</a></li>
<li><a href="#pca-主成分分析"><span class="toc-section-number">7.2</span> PCA 主成分分析</a><ul>
<li><a href="#主成分principal-component"><span class="toc-section-number">7.2.1</span> 主成分（Principal Component）</a></li>
<li><a href="#映射"><span class="toc-section-number">7.2.2</span> 映射</a></li>
<li><a href="#压缩"><span class="toc-section-number">7.2.3</span> 压缩</a></li>
<li><a href="#增量-pca"><span class="toc-section-number">7.2.4</span> 增量 PCA</a></li>
<li><a href="#randomized-pca"><span class="toc-section-number">7.2.5</span> Randomized PCA</a></li>
</ul></li>
<li><a href="#kernel-pca"><span class="toc-section-number">7.3</span> Kernel PCA</a></li>
<li><a href="#lle-locally-linear-embedding"><span class="toc-section-number">7.4</span> LLE (Locally Linear Embedding)</a></li>
</ul></li>
</ul>
</nav>
<h1 id="end-to-end-machine-learning-project"><span class="header-section-number">1</span> End-to-End Machine Learning Project</h1>
<p>通常的步骤 checklist:</p>
<ul>
<li>Frame the problem and look at the big picture</li>
<li>Get the data</li>
<li>Explore the data to gain insights</li>
<li>Prepare the data to better expose the underlying data patterns to Machine Learning algorithms</li>
<li>Explore many different models and combine them into a great solution</li>
<li>Present your solution</li>
<li>Launch, monitor, and maintain your system.</li>
</ul>
<h2 id="frame-the-problem-and-look-at-the-picture"><span class="header-section-number">1.1</span> Frame the problem and look at the picture</h2>
<h3 id="确定问题"><span class="header-section-number">1.1.1</span> 确定问题</h3>
<p>最开始的是需要确定问题：模型在当前整个系统或者任务中充当一个什么样的角色；在系统中处于一个什么样的位置；当前的解决方案是什么，有什么样的问题，效果如何。确定了这些问题之后，自然就形成了问题解决的整体框架（监督/非监督、批量学习/在线学习/强化学习、分类/回归等）。</p>
<h3 id="选择性能指标"><span class="header-section-number">1.1.2</span> 选择性能指标</h3>
<p>如果是分类问题，如果是二分类且数据集平衡，会考虑传统的 Accuacy, Precision, F1 等指标，如果数据非平衡，则 AUC, ROC 等指标，进一步的，如果数据非平衡还是多分类，则考虑混淆矩阵等指标。</p>
<p>而对于回归问题，常见的指标是 <em>Root Mean Square Error (RMSE)</em>：<span class="math display">\[\text{RMSE}(X,h)=\sqrt{\frac{1}{m}\sum_{i=1}^m(h(x^{(i)})-y^{(i)})^2}\]</span></p>
<p>或者 <em>Mean Absolute Error (MAE)</em>：<span class="math display">\[\text{MAE}(X,h)=\frac{1}{m}\sum_{i=1}^m{\lvert}h(x^{(i)})-y^{(i)}\rvert\]</span></p>
<h3 id="检验假设"><span class="header-section-number">1.1.3</span> 检验假设</h3>
<p>建模时，我们通常都会做出很多假设（比如iid），但是在建模之前就对这些假设的可行性以及必要性进行确定。比如，通常价格预测会是一个回归问题，但是如果系统中接受模型输出的下一个模块其实也是将模型预测出的输出转换成了“便宜”、“普通”、“昂贵”三个类别，那么将该问题看作是回归问题就非常不明智了，这中间会损失一些信息，并且下游系统不太关心预测的结果是否精准，只关心类别是否正确。</p>
<h2 id="get-the-data"><span class="header-section-number">1.2</span> Get the Data</h2>
<h3 id="大概的观察数据"><span class="header-section-number">1.2.1</span> 大概的观察数据</h3>
<p>拿到数据并加载后，使用<code>pandas.DataFrame.info()</code>对数据进行初步的观察：总共有多少样本量、每个属性的类型、有多少缺失等。这涉及到后续预处理需要进行哪些操作。对于数字类型属性，使用<code>pandas.DataFrame.describe()</code>对其统计信息进行一个大致的汇总观察。最后，再使用各种图表进行直观的观察。</p>
<h3 id="创建测试集"><span class="header-section-number">1.2.2</span> 创建测试集</h3>
<p>测试集的重要性无需再提，也不用说训练前不要观察训练集的话题，但是一个经常忽略的问题是多次训练后的信息泄漏：</p>
<pre><code>想象这样的一个场景，数据被一起保存在一个文件夹下，每次训练的时候都重新随机切分数据为训练集和测试集，随后使用训练集来进行模型训练，测试集来进行模型的效果评估。</code></pre>
<p>大致看来，这样做没有什么问题，每一次模型训练时都使用<code>train_test_split()</code>保留了测试集进行模型的评估。但是这后面有一个存在着测试数据信息泄漏的致命缺陷：每一次的重新训练，都会重新随机切分训练集和测试集，每一次的测试集都不相同，随着训练次数的增加，最终我们还是得到了测试集的信息，并有可能影响了我们观察数据后对模型选择的倾向。</p>
<p>一个解决办法是在第一次接触数据时就切分好数据进行保存，另一个解决办法是在切分时指定随机种子以便每一次生成相同的随机序列。但是两者都不保险，一个典型的场景就是当有新的数据添加进来时，两种方式都又会产生新的样本序列。可以针对样本计算 hash 值来解决，方式是计算出样本的 hash 值，当其特定位小于一定比例值时，将其归入测试集。还有的做法是使用样本的 index 作为切分测试集的指标，但是这种方式需要保证新增的样本是以追加的方式添加到数据集中。</p>
<h2 id="discover-and-visualize-the-data-to-gain-insights"><span class="header-section-number">1.3</span> Discover and Visualize the Data to Gain Insights</h2>
<h3 id="观察数据属性之间的关系"><span class="header-section-number">1.3.1</span> 观察数据属性之间的关系</h3>
<p>可以通过<code>pandas.DataFrame.corr()</code>来技术属性之间的协方差关系，但是需要注意的是协方差仅能观察到线性关系，对非线性关联关系却是无能为力。</p>
<h3 id="尝试对一部分属性进行组合"><span class="header-section-number">1.3.2</span> 尝试对一部分属性进行组合</h3>
<p>通过一些属性构造一些新的属性来进行进一步的观察。</p>
<h2 id="prepare-the-data-for-machine-learning-algorithms"><span class="header-section-number">1.4</span> Prepare the Data for Machine Learning Algorithms</h2>
<p>获取数据后，大致上需要以下几个步骤对数据进行处理才能进入模型进行训练：</p>
<ol type="1">
<li>Data Cleaning: 包括确实值处理、属性转换等；</li>
<li>Handing Text and Categorical Attributes:</li>
<li>Feature Scaling: Min-Max Scaling and Standardization，Min-Max 的方式简单，将值压缩在 <span class="math inline">\(0~1\)</span> 范围内，但是易受异常点的影响，而 Standardization 不易受到异常点的影响，但是其值的范围是 <span class="math inline">\(-1~1\)</span>，对于某些算法（神经网络需要<span class="math inline">\(0~1\)</span>）使用法直接使用这些数据的。</li>
</ol>
<p>整个特征转换的过程可以通过自定义 Transformers 来进行优化组织。Scikit-Learn 使用 duck typing 的形式来组织功能，因此如果一个类实现了 <code>fit()</code>、<code>transform()</code>和<code>fit_transform()</code>方法就可以算是一个 Transformer。如果继承自<code>TransformerMixin</code>父类，则可以省略掉显式定义<code>fit_transform()</code>的过程。此外，如果继承<code>BaseEstimator</code>父类（但是初始化函数中不能使用<code>*args</code>或<code>**kargs</code>），则可以使用<code>get_params()</code>和<code>set_params()</code>两个函数来进行超参 tuning。</p>
<h2 id="select-and-train-a-model"><span class="header-section-number">1.5</span> Select and Train a Model</h2>
<blockquote>
<p>You should save every model you experiment with, so you can come back easily to any model you want. Make sure you save both the hyperparameters and the trained parameters, as well as the cross-validation scores and perhaps the actual predictions as well. This will allow you to easily compare scores across model types, and compare the types of erros the make.</p>
</blockquote>
<h2 id="fine-tune-your-model"><span class="header-section-number">1.6</span> Fine-Tune Your Model</h2>
<p>在尝试好模型后，可以通过以下多种方式来调整模型：</p>
<ul>
<li><code>GridSearchCV</code>或者<code>RandomSearchCV</code>来寻找最优的超参</li>
<li>将已经试验好的多个模型，分析其预测结果，对于差异化的模型进行集成</li>
<li>分析模型的结果</li>
</ul>
<h1 id="classification"><span class="header-section-number">2</span> Classification</h1>
<h2 id="性能评价指标"><span class="header-section-number">2.1</span> 性能评价指标</h2>
<p>对于不平衡数据集，一个典型的指标就是混淆矩阵。</p>
<p>通常都会有 precision/recall tradeoff 问题，可以通过绘制 PR 曲线进行观察。</p>
<blockquote>
<p>If some says “let’s reach 99% precision,” you should ask, “at what recall?”</p>
</blockquote>
<p>此外，还可以通过绘制 ROC 并计算 AUC 来评估模型的性能。</p>
<p>至于 ROC 和 PR 曲线的使用时机的选择，一个简单的判断条件是，如果 positive class 很少或者我们相对于 false negatives 而言更关心 false positives 时，都应该使用 PR 曲线，其他时候都优先选择 ROC 曲线。</p>
<h1 id="training-models"><span class="header-section-number">3</span> Training Models</h1>
<h2 id="梯度下降"><span class="header-section-number">3.1</span> 梯度下降</h2>
<p>线性回归中损失函数为 MSE 时恰好是一个凸优化问题，因此使用梯度下降肯定可以得到全剧最优解。</p>
<p>梯度下降根据每次迭代使用的样本数量大小分为了以下三种类型：</p>
<ul>
<li>批量梯度下降：每一步梯度计算时都会使用全部训练集进行计算；</li>
<li>随机梯度下降：每一步梯度计算时只使用一个随机的训练样本进行训练，由于每一次迭代时只需要一个样本，因此非常适合于数据量大且内存无法装载的场景，但是由于每一次样本都是随机选择，因此其趋向于最优的过程并非是一直趋向于最优，而是“在振荡中趋向于最优”，并且由于该“振荡”性，最终寻找到的结果并非是最优，而是最优附近的结果。而由于其随机性，随机梯度下降比批量梯度下降更容易找到全局最优。</li>
<li>小批量梯度下降：前面两种方式的结合，每次迭代时随机选择一定数量的样本进行计算。小批量梯度下降相比随机梯度下降在全局最优解周围更容易稳定下来，但是却更容易桎梏于某些局部最优解。</li>
</ul>
<h2 id="polynomial-regression"><span class="header-section-number">3.2</span> Polynomial Regression</h2>
<blockquote>
<p>What if your data is actually more compelx than a simple straight line? Surprisingly, you can actually use a linear model to fit nonlinear data. A simple way to do this is to add powers of each feature as new features, then train a linear model on this extended set of features. This technique is called <em><strong>Polynomial Regression</strong></em>.</p>
</blockquote>
<h3 id="学习曲线learning-curve"><span class="header-section-number">3.2.1</span> 学习曲线（Learning Curve）</h3>
<p>印象中，好像有个理论是说“多项式可以拟合任意曲线”？</p>
<p>因此，对于任意数据集我们都可以使用足够复杂的多项式特征去进行拟合，但是这中间过拟合/欠拟合的度是非常不好把握的，因此可以使用 <strong>学习曲线</strong> 来进行判定当前模型是过拟合还是欠拟合。如果模型在训练集上仍然是处于欠拟合的状态，那么意图以增加数据量的方式来提高模型的效果无疑是徒劳的。</p>
<hr />
<p><strong>The Bias/Variance Tradeoff</strong>:</p>
<p>Increasing a model’s complexity will typically increase its variance and reduce its bias. Conversely, reducing a model’s complexity increases its bias and reduces its variance.</p>
<hr />
<h2 id="对线性模型进行正则化"><span class="header-section-number">3.3</span> 对线性模型进行正则化</h2>
<p>过多的特征，但是只有很少的数据，会导致过拟合，为了解决该问题，有两种方式：</p>
<ol type="1">
<li>减少特征（特征降维、特征选择）</li>
<li>正则化，保留所有特征，但是减小特征变量的数量级，保证每一个变量都只对结果产生一点点的影响，特征对应的权重越小，通常对应越是光滑的函数，也就是更加简单的函数，更加不容易出现过拟合。</li>
</ol>
<p>对于过拟合，一个经验是对模型正则化（regularization）：模型越不自由，越不可能出现过拟合。进行正则化的方式有多种，对于多项式模型正则化的方式是减少多项式的“度”，而对于线性模型，正则化的方式是 constraining the weights of the model。</p>
<h3 id="ridge-regression"><span class="header-section-number">3.3.1</span> Ridge Regression</h3>
<p>Ridge Regression 是正则化版本的线性回归，它在线性回归的损失函数 MSE 的基础上增加了一个正则化罚项 <span class="math inline">\(\alpha\sum_{i=1}^n\theta_i^2\)</span>，因此最终的损失函数为：</p>
<p><span class="math display">\[J(\theta)=\text{MSE}(\theta)+\alpha\frac{1}{2}\sum_{i=1}^n\theta_i^2\]</span></p>
<p>注意其中<span class="math inline">\(\theta_0\)</span>并未进行正则化，而且整个正则罚项只在训练时添加，一旦模型训练完毕，使用没有正则罚项的损失函数来计算模型的性能。</p>
<p>这听起来看上去很奇怪，训练时使用一个指标，而在测试时使用另一个指标。但是实际上，抛开正则的因素，训练时通常需要构造一个连续可导的损失函数来进行优化，而测试时需要使用最终关心的指标来进行计算，一个常见的例子就是使用 log loss 作为分类器训练的损失函数，但是使用精确度/召回率作为最终的指标。</p>
<p><small><span class="math inline">\(\Vert\cdot\Vert_2\)</span>表示的是权重向量中的<span class="math inline">\(\ell_2\)</span>正则项</small></p>
<h3 id="lasso-regression"><span class="header-section-number">3.3.2</span> Lasso Regression</h3>
<p><em>Least Absolute Shrinkage</em> and <em>Selection Operator Regression</em> (简称为 Lasso Regression) 也是一种线性回归，和 Ridge Regression 的不同之处在于其对应的罚项是<span class="math inline">\(\ell_1\)</span>:</p>
<p><span class="math display">\[J(\theta)=MSE(\theta)+\alpha\sum_{i=1}^n\lvert\theta_i\rvert\]</span></p>
<p>对应的区别是 Lasso Regression 会趋向于忽视不那么重要特征的权重。因此，Lasso Regression 会自动做特征选择并且输出稀疏模型。</p>
<h3 id="early-stopping"><span class="header-section-number">3.3.3</span> Early Stopping</h3>
<p>这种正则化方式是 Geoffrey Hinton 口中的“beautiful free lunch”。具体的方式就是在梯度下降迭代时，当在验证集上的效果达到理想的值时停止迭代。</p>
<h3 id="elastic-net"><span class="header-section-number">3.3.4</span> Elastic Net</h3>
<blockquote>
<p>Elastic Net is a middle ground between Ridge Regression and Lasso Regression.</p>
</blockquote>
<p><span class="math display">\[J(\theta)=MSE(\theta)+r\alpha\sum_{i=1}^n\lvert\theta_i\rvert+\frac{1-r}{2}\alpha\sum_{i=1}^n\theta_i^2\]</span></p>
<p>对于各种正则化的选择，通常默认是 Ridge Regression，但是如果怀疑特征中有大量的无用的特征，可以使用 Lasso Regression 或者 Elastic Net，而 Elastic Net 又优先于 Lasso Regression，因为 Lasso Regression 在特征数大于训练样本数或有几个特征强相关时会表现得极不规律，因此通常这种场景下会优先使用 Elastic Net。</p>
<h2 id="逻辑回归"><span class="header-section-number">3.4</span> 逻辑回归</h2>
<p>逻辑回归预测所属类别的概率的方式是：</p>
<p><span class="math display">\[\hat{p}=h_{\theta}(x)=\sigma(\theta^T{\cdot}x)\]</span></p>
<p>其中</p>
<p><span class="math display">\[\sigma(t)=\frac{1}{1+\text{exp}(-t)}\]</span></p>
<p>而根据计算所得的概率值<span class="math inline">\(\hat{p}=h_{\theta}(x)\)</span>，可以很容易的得到所属的类别：</p>
<p><span class="math display">\[
\hat{y}=
\begin{cases}
    0 &amp; \text{if } \hat{p}\lt0.5\\
    1 &amp; \text{if } \hat{p}\ge0.5
\end{cases}
\]</span></p>
<h3 id="损失函数"><span class="header-section-number">3.4.1</span> 损失函数</h3>
<p>单个训练样本的损失函数为：</p>
<p><span class="math display">\[
c(\theta)=
\begin{cases}
    -\log(\hat{p})&amp; \text{if }y=1\\
    -\log(1-\hat{p})&amp; \text{if}y=0.
\end{cases}
\]</span></p>
<p>不管预测正例样本还是负例样本，如果其预测的概率趋向于0时，其对应的损失函数都会趋向于无穷大。而针对整个样本集的损失函数为所有损失的平均，名为 <em>log loss</em>：</p>
<p><span class="math display">\[J(\theta)=-\frac{1}{m}\sum_{i=1}^m{\lbrack}y^{(i)}\log(\hat{p}^{(i)})+(1-y^{(i)})\log(1-\hat{p}^{(i)})\rbrack\]</span></p>
<p><sup>默认情况下，<code>sklearn</code>中的逻辑回归的损失函数默认添加了<span class="math inline">\(\ell_2\)</span>罚项</sup></p>
<h2 id="softmax-regression"><span class="header-section-number">3.5</span> Softmax Regression</h2>
<p>当逻辑回归泛化到多分类领域，就是 Softmax Regression，或者叫 Multinomial Logistic Regression。Softmax Regression 首先会计算每个类<span class="math inline">\(k\)</span>的得分<span class="math inline">\(s_k(x)\)</span>，然后在该得分上使用 <em>softmax function</em> 计算属于该类的概率。</p>
<p><span class="math display">\[s_k(x)=\theta_k^T\cdot{x}\]</span></p>
<p>所有类的<span class="math inline">\(\theta_k\)</span>组成了一个参数矩阵<span class="math inline">\(\Theta\)</span>。计算属于类<span class="math inline">\(k\)</span>的概率的方式是使用 softmax function：</p>
<p><span class="math display">\[\hat{p}_k=\sigma(s(x))_k=\frac{\text{exp}(s_k(x))}{\sum_{j=1}^K\text{exp}(s_j(x))}\]</span></p>
<p>其中，<span class="math inline">\(s(x)\)</span>是样本<span class="math inline">\(x\)</span>属于每个类的得分向量。计算出结果后，取属于最高概率的类。</p>
<p>Softmax Regression 的损失函数为交叉熵，该损失函数通常用于评价类别归属问题：</p>
<p><span class="math display">\[J(\Theta)=-\frac{1}{m}\sum_{i=1}^m\sum_{k=1}^Ky_k^{(i)}\log(\hat{p}_k^{(i)})\]</span></p>
<p><sup>当类别只有两类时，该损失函数其实就是逻辑回归的损失函数。</sup></p>
<h1 id="support-vector-machines-svm"><span class="header-section-number">4</span> Support Vector Machines (SVM)</h1>
<blockquote>
<p>SVMs are particularly well suited for classification of complex but small- or medium-sized datasets.</p>
</blockquote>
<p>SVM 的决策边界（decision boundaries）只由支持向量影响，因此增加更多的训练样本不见得会影响该决策边界。</p>
<p><sup>SVM算法对scale敏感，一次使用之前需要进行scale，否则最终的决策边界会“倒向”较大值的坐标轴，导致最终的决策边界比实际要小。</sup></p>
<h2 id="soft-margin-classification"><span class="header-section-number">4.1</span> Soft Margin Classification</h2>
<p>SVM 的核心是寻找 decision boundaries，如果严格按照样本来进行类别划分的话（ <em>hard margin classification</em> ），一旦样本中包含噪声，极有可能会将决策边界带偏。为了解决该问题，引入了 <em>soft margin classification</em>，其目的在于在增大支持向量间的距离和 limiting the margin violations 之间做出平衡。在<code>sklean</code>中，SVM 相关的类通过参数<code>C</code>来控制该平衡：当<code>C</code>越大时，支持向量中间包含的样本点越少，但是支持向量之间的距离越小，反之则样本边界之间包含的样本点较多，但是支持向量之间的距离越大。因此，如果 SVM 模型过拟合，可以考虑降低<code>C</code>值。</p>
<h2 id="非线性-svm"><span class="header-section-number">4.2</span> 非线性 SVM</h2>
<h3 id="polynomial-kernel"><span class="header-section-number">4.2.1</span> Polynomial Kernel</h3>
<p>通常大多数的分类问题并非是线性可分，一个解决办法就是使用前面的增加多项式特征的方式，但是多项式特征的“度数”却是很难拿捏，太低无法解决复杂的问题，太高又会造成模型速度过慢。但是在 SVM 模型中，可以通过一种叫做 <em>kernel trick</em> 的方式达到和引入了多项式变量同样的效果（但是却未真的引入）。</p>
<p><code>sklearn</code>中的 SVM 类引入非线性多项式特征的方式为：<code>SVC(kernel='poly', degree=3, coef0=1, C=5)</code>。</p>
<h3 id="adding-similarity-features"><span class="header-section-number">4.2.2</span> Adding Similarity Features</h3>
<p>另外一种解决非线性分类问题的方式是通过使用某些相似函数计算每个样本和某个特殊的 landmark 的相似度来作为新的特征添加到样本的特征向量中。</p>
<p>举个一维向量样本的例子，假设为该样本集选择了两个 landmark：<span class="math inline">\(x_1=-2\)</span> 和 <span class="math inline">\(x_1=1\)</span>，并且使用 <em>Gaussian Radial Basis Function (RBF)</em> 作为相似度函数为：<span class="math display">\[\phi_\gamma(x,\ell)=\text{exp}(-\gamma{\Vert}x-\ell\Vert^2)\]</span> 其中 <span class="math inline">\(\gamma=0.3\)</span>。</p>
<p>该函数是一个典型的钟形函数（当靠近 landmark 时，值趋向于 1，而远离 landmark 时，值趋向于 0），其中 <span class="math inline">\(\gamma\)</span> 用于控制该钟形函数形状的“宽窄”程度，在本例中，对于 <span class="math inline">\(x_1=-1\)</span> 的样本，对应的新特征为 <span class="math inline">\(x_2=\text{exp}(-0.3{\times}1^2){\approx}0.74\)</span>、<span class="math inline">\(x_3=\text{exp}(-0.3{\times}2^2){\approx}0.30\)</span>，经过该转换后，由 <span class="math inline">\(x_2\)</span> 和 <span class="math inline">\(x_3\)</span> 两种特征（丢弃原始特征）组成的新样本变得线性可分。</p>
<p>该种方式中，landmark 的选择是一个大问题，一个简单的方式是将所有样本都作为 landmark 来生成新特征，这样一个原本 m 个样本（n 个特征）组成的样本集转换成了 m 个样本（m 个特征）的新样本集，因此如果样本众多的时候该方式会生成大量的特征，导致计算速度降低。</p>
<p>该种方式和多项式方式一样，都是适用于所有的机器学习算法，但是也有同样的问题，就是计算开销非常大，当训练样本集较大时尤为如此。</p>
<h3 id="gaussian-rbf-kernel"><span class="header-section-number">4.2.3</span> Gaussian RBF Kernel</h3>
<p>添加相似特征的方式需要庞大的计算开销，而在 SVM 中，通过一定的 kernel trick 却可以实现类似的效果，但是却无需真正的添加这些新特征。</p>
<p>前面说过，在相似度函数中，增大 <span class="math inline">\(\gamma\)</span> 会使该形状变窄，降低 <span class="math inline">\(\gamma\)</span> 则使的该形状变宽。变窄变宽的区别是，当较窄时，每个样本的影响范围将变小，导致 SVM 的决策边界不规则且在单个样本周围摆动，反之，较宽的钟形函数导致每个样本的影响范围增大，决策边界更加光滑。因此这里 <span class="math inline">\(\gamma\)</span> 也类似于是一个正则化超参：如果模型过拟合，则降低它的值，如果欠拟合，则增加它的值。</p>
<p>对于这些“核”的选择，通常应该首先使用线性核进行尝试（尤其是在样本集较大或者特征较多时），尝试线性核应该要知道<code>LinearSVC</code>的速度比<code>SVC(kernel="linear")</code>要快得多。如果训练集不是那么大，可以尝试 Gaussian RBF，通常情况下它都会工作的很好。</p>
<p>造成 <code>LinearSVC</code> 和 <code>SVC(kernel="linear")</code> 区别的原因是，<code>LinearSVC</code> 是基于 <code>liblinear</code> 库，该库针对线性 SVM 有所优化，优化的代价是不支持 kernel trick，换来的结果是时间复杂度仅是 <span class="math inline">\(O(m{\times}n)\)</span>。而 <code>SVC</code> 则是基于 <code>libsvm</code> 库，该库支持 kernel trick，但是时间复杂度却通常为 <span class="math inline">\(O(m^2{\times}n)\)</span> 到 <span class="math inline">\(O(m^3{\times}n)\)</span> 之间，这导致随着样本数量的增长，性能将会急剧下降，但是性能和特征的增长只呈正比关系。</p>
<table>
<thead>
<tr class="header">
<th>Class</th>
<th>Time complexity</th>
<th>Out-of-core support</th>
<th>Scaling required</th>
<th>Kernel trick</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>LinearSVC</td>
<td><span class="math inline">\(O(m{\times}n)\)</span></td>
<td>No</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr class="even">
<td>SGDClassifier</td>
<td><span class="math inline">\(O(m{\times}n)\)</span></td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr class="odd">
<td>SVC</td>
<td><span class="math inline">\(O(m^2{\times}n)\)</span> to <span class="math inline">\(O(m^3{\times}n)\)</span></td>
<td>No</td>
<td>Yes</td>
<td>Yes</td>
</tr>
</tbody>
</table>
<h2 id="svm-回归"><span class="header-section-number">4.3</span> SVM 回归</h2>
<p>使用 SVM 建立回归模型只需将分类模型的目标反过来：分类时是尽力建立足够宽的支持向量来将所有点分割在支持向量两边，而回归则是尽量将所有点都包含在支持向量之间，两者都允许一定的 margin violations（只是 violations 的定义不同，前者是说在支持向量之间算是 violations，而后者是说在支持向量之外算是 violations）。回归中支持向量之间的距离由 <span class="math inline">\(\epsilon\)</span> 来控制。</p>
<p>和分类一样，回归时也分 <code>LinearSVR</code> 和 <code>SVR</code>，两者的区别也和前面相同。解决非线性回归问题时也可以使用核技巧，<code>C</code> 参数控制正则化来控制拟合情况。</p>
<h2 id="under-the-hood"><span class="header-section-number">4.4</span> Under the Hood</h2>
<p>线性 SVM 的原理很简单，其决策函数为：</p>
<p><span class="math display">\[
\hat{y}=
\begin{cases}
    0&amp; \text{if }w^T{\cdot}x+b{\lt}0,\\
    1&amp; \text{if }w^T{\cdot}x+b{\ge}0
\end{cases}
\]</span></p>
<p>比如，对于一个只有两个特征的样本，其样本分布于一个二维平面，则线性 SVM 的决策函数则是三维空间（第三维坐标是决策函数 <span class="math inline">\(h=w^t{\cdot}x+b\)</span> 中 <span class="math inline">\(h\)</span> 的取值）中的一个超平面，该超平面对于二维平面中 positive 类别来说其 <span class="math inline">\(h\)</span> 值是大于 0 的部分，而对于 negative 的样本来说是 <span class="math inline">\(h\)</span> 值小于 0 的部分。当超平面中 <span class="math inline">\(h=+1\)</span> 和 <span class="math inline">\(h=-1\)</span> 的平行的两条边映射到二维平面上则是支持向量。因此线性 SVM 的目的则是找到 <span class="math inline">\(w\)</span> 和 <span class="math inline">\(b\)</span> 使得在保持足够少的 margin violations 的前提条件下并且支持向量之间的距离足够宽。</p>
<h3 id="训练目标"><span class="header-section-number">4.4.1</span> 训练目标</h3>
<p>前面所述的超平面的斜率即是 <span class="math inline">\(\Vert{w}\Vert\)</span>，如果对其除以 2，则超平面映射到二维平面上的支持向量之间的距离就要增大 2 倍，因此一个浅而易见的目标就是最小化 <span class="math inline">\(\Vert{w}\Vert\)</span>，如果我们选择 hard margin，那么对于所有的 positive 样本，我们需要它决策函数值大于 1，而对于 negative 的样本需要其决策函数值小于 1。因此我们可以定义一个变量 <span class="math inline">\(t^{(i)}\)</span>，对于 positive 样本 <span class="math inline">\(t^{(i)}{\gt}1\)</span>，而对于 negative 样本 <span class="math inline">\(t^{(i)}{\lt}1\)</span>，这样对于所有样本我们的限制条件就是 <span class="math inline">\(t^{(i)}(w^T{\cdot}x+b){\ge}1\)</span>。</p>
<p>因此最终线性 SVM 的优化目标为：</p>
<p><span class="math display">\[\underset{w,b}{\text{minimize}}\text{ }\frac{1}{2}w^T{\cdot}w\]</span></p>
<p><span class="math display">\[\text{subject to }t^{(i)}(w^T{\cdot}x^{(i)}+b){\ge}1\text{ for }i=1,2,...,m\]</span></p>
<p>而对于 soft margin，对每个变量引入 <em>slack variable</em> <span class="math inline">\(\zeta^{(i)}{\ge}1\)</span>，该变量用于衡量第 i 个样本可以 violate the margin 的程度。因此目前为止，我们有两个有些冲突的优化目标：(1) <span class="math inline">\(\zeta^{(i)}\)</span> 需要尽量小以尽量避免 margin violations，另一方面还需要使 <span class="math inline">\(\frac{1}{2}w^T{\cdot}w\)</span> 尽量小以使支持向量尽量宽。所以需要引入 <span class="math inline">\(C\)</span> 参数来控制两者的 tradeoff：</p>
<p><span class="math display">\[\underset{w,b,\zeta}{\text{minimize}}\text{  }\frac{1}{2}w^T{\cdot}w+C\sum_{i=1}^m\zeta^{(i)}\]</span></p>
<p><span class="math display">\[\text{subject to }t^{(i)}(w^T{\cdot}x^{(i)}+b){\ge}1-\zeta^{(i)}\text{ and }\zeta^{(i)}{\ge}0\text{ for }i=1,2,\cdots,m\]</span></p>
<h3 id="quadratic-programming"><span class="header-section-number">4.4.2</span> Quadratic Programming</h3>
<p>线性 SVM 的 hard margin 和 soft margin 问题都是线性约束的凸二次优化问题，该类问题也叫 Quadratic Programming (QP) 问题。该类问题的解决方式非常成熟，因此求解线性 SVM 的最优可以简单的使用该领域的方式解决。</p>
<h3 id="对偶问题"><span class="header-section-number">4.4.3</span> 对偶问题</h3>
<p>为了使用 kernel trick，我们需要对原始的问题进行一些变化已解决另外更“友好”的约束优化问题。</p>
<p>在约束优化问题中，原问题通常可以表述为一个相近的对偶问题，对偶问题的解通常是原问题的下界，但是满足一定条件后，两者的解甚至可以想同。而 SVM 刚好满足该条件，因此 SVM 和其对偶问题都拥有相同解。SVM 的对偶问题的形式为：</p>
<p><span class="math display">\[\underset{\alpha}{\text{minimize}}\text{  }\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m\alpha^{(i)}\alpha^{(j)}t^{(i)}t^{(j)}x^{(i)^T}{\cdot}x-\sum_{i=1}^m\alpha^{(i)}\]</span> <span class="math display">\[\text{subject to }\alpha^{(i)}{\ge}0\text{ for }i=1,2,\cdots,m\]</span></p>
<p>一旦使用 QP solver 求解出最优的 <span class="math inline">\(\hat{\alpha}\)</span>，就可以使用以下公式计算出对应的原问题的最优解：</p>
<p><span class="math display">\[\hat{w}=\sum_{i=1}^m\hat{\alpha}^{(i)}t^{(i)}x^{(i)}\]</span> <span class="math display">\[\hat{b}=\frac{1}{n_s}\sum_{\stackrel{i=1}{\hat{\alpha^{(i)}{\gt}0}}}^m(1-t^{(i)}(\hat{w}^T{\cdot}x^{(i)}))\]</span></p>
<p>当样本数小于特征数时，求解对偶问题速度相对原问题较快，更为重要的，求解对偶问题可以使用核技巧。</p>
<h3 id="kernelized-svm"><span class="header-section-number">4.4.4</span> Kernelized SVM</h3>
<p>假设对于一个二维的样本做了 2nd-degree 的多项式变换，则变换后的样本为：</p>
<p><span class="math display">\[
\phi(x)=\phi\lgroup
\begin{bmatrix}
    x_1\\
    x_2
\end{bmatrix}
\rgroup=
\begin{bmatrix}
    x_1^2\\
    \sqrt{2}x_1x_2\\
    x_2^2
\end{bmatrix}
\]</span></p>
<p>假设有两个二维的变量 <span class="math inline">\(a\)</span> 和 <span class="math inline">\(b\)</span>，对其进行多项式变化并计算内积则有：</p>
<p><span class="math display">\[
\phi{a}^T{\cdot}\phi{b}=
\begin{bmatrix}
    a_1^2\\
    \sqrt{2}a_1a_2\\
    a_2^2
\end{bmatrix}\cdot
\begin{bmatrix}
    b_1^2\\
    \sqrt{2}b_1b_2\\
    b_2^2
\end{bmatrix}=a_1^2b_1^2+2a_1b_1a_2b_2+a_2^2b_2^2=(a_1b_1+a_2b_2)^2=
\begin{bmatrix}
    \begin{bmatrix}
        a_1\\
        a_2
    \end{bmatrix}^T\cdot
    \begin{bmatrix}
        b_1\\
        b_2
    \end{bmatrix}
\end{bmatrix}^2=(a^T{\cdot}b)^2
\]</span></p>
<p>即有：<span class="math inline">\(\phi{a}^T{\cdot}\phi{b}=(a^T{\cdot}b)^2\)</span>，假设对所有样本做 <span class="math inline">\(\phi\)</span> 变换，那么有前面的公式可知，其对偶问题肯定包含内积 <span class="math inline">\(\phi(x^{(i)})^T{\cdot}\phi{x^{(j)}}\)</span>，但是该内积形式其实就等于 <span class="math inline">\((x^{(i)^T}{\cdot}x^{(j)})^2\)</span>。因此其实从头到尾并不需要对原来的样本做 <span class="math inline">\(\phi\)</span> 变换。<span class="math inline">\(K(a,b)=(a^T{\cdot}b)^2\)</span> 称为 2nd-degree 多项式核。</p>
<p>在机器学习中，“核” <span class="math inline">\(K(a,b)\)</span> 表示如果计算 <span class="math inline">\(\phi(a)^T{\cdot}\phi(b)\)</span> 时，只需使用原始的 <span class="math inline">\(a\)</span> 和 <span class="math inline">\(b\)</span> 进行计算而无需使用变换后的 <span class="math inline">\(\phi{a}\)</span> 和 <span class="math inline">\(\phi{b}\)</span>。常见的核为：</p>
<ul>
<li><span class="math inline">\(\text{Linear: }K(a,b)=a^T{\cdot}b\)</span></li>
<li><span class="math inline">\(\text{Polynomial: }K(a,b)=(\gamma{a}^T{\cdot}b+r)^d\)</span></li>
<li><span class="math inline">\(\text{Gaussian RBF: }K(a,b)=\text{exp}(-\gamma\Vert{a-b}\Vert^2)\)</span></li>
<li><span class="math inline">\(\text{Sigmoid: }K(a,b)=\tanh(\gamma{a}^T{\cdot}b+r)\)</span></li>
</ul>
<p><sup>根据Mercer’s定理，如果满足一定的条件（<span class="math inline">\(K\)</span>连续、对称），则一定存在有一个函数<span class="math inline">\(\phi\)</span>将<span class="math inline">\(a\)</span>和<span class="math inline">\(b\)</span>映射到另一个空间使的<span class="math inline">\(K(a,b)=\phi{a}^T{\cdot}\phi{b}\)</span>，因此在日常使用时，我们可能并不需要知道<span class="math inline">\(\phi\)</span>是一个什么样的形式，但是我们知道它一定存在，从而可以做进一步的变换。</sup></p>
<h3 id="online-svms"><span class="header-section-number">4.4.5</span> Online SVMs</h3>
<p>对于线性 SVM 分类器，虽然可以使用梯度下降（<code>SGDClassifier</code>）最小化损失函数的方式来直接对原问题进行求解，但是其收敛速度却远远慢于基于 QP 的方法。</p>
<p><span class="math display">\[J(w,b)=\frac{1}{2}w^T{\cdot}w+C\sum_{i=1}^m\max(0,1-t^{(i)}(w^T{\cdot}x^{(i)}+b))\]</span></p>
<p>该损失函数前面半部分用于尽量加宽支持向量间的距离，后半部分则对 margin violations 进行惩罚，两者之间使用 <span class="math inline">\(C\)</span> 来进行权衡。<span class="math inline">\(\max(0,1-t)\)</span> 为 Hinge Loss 函数。</p>
<h1 id="decision-tree"><span class="header-section-number">5</span> Decision Tree</h1>
<p>通过一定方式（信息增益、信息熵）选择出的当前最佳特征，将训练集分割成基本正确的子集。当来自新的样本后，根据训练时依据的特征顺序查看样本所属的类别。</p>
<p>该算法可用于分类也可用于回归，当用于回归时，则根据决策树决定的最终的叶子结点中所有样本的均值作为最终结果。速度方面，由于计算时需要从根节点到叶子结点进行比较，因此一次完成的分类/预测只需要对比 <span class="math inline">\(O(\log_2(m))\)</span> 个结点，因此速度非常快。</p>
<h2 id="训练算法"><span class="header-section-number">5.1</span> 训练算法</h2>
<h3 id="cart-classification-and-regression-tree"><span class="header-section-number">5.1.1</span> CART (Classification And Regression Tree)</h3>
<p>每次选择特征作为分割结点时，都尽量达到分割后的子集更纯的目的，而度量“更纯”可以使用两种方式：</p>
<ul>
<li>Gini 系数： <span class="math inline">\(G_i=1-\sum_{k=1}^np_{i,k}^2\)</span> ，其中 <span class="math inline">\(p_{i,k}\)</span> 为第 i 个结点时类别 k 的样本数；</li>
<li>信息熵： <span class="math inline">\(H_i=-\sum_{k=1}^np_{i,k}\log(p_{i,k})\)</span> 。</li>
</ul>
<p>两者的区别在于，Gini 系数的计算相对较快，而使用信息熵则会生成更加平衡的决策树。</p>
<p>整个算法对应的损失函数为：</p>
<p><span class="math display">\[J(k,t_k)=\frac{m_{left}}{m}G_{left}+\frac{m_{right}}{m}G_{right}\]</span></p>
<p>其中 <span class="math inline">\(G_{left/right}\)</span> 分别表示左右子树的“纯度”，而 <span class="math inline">\(m_{left/right}\)</span> 分别表示左右子树的样本数。</p>
<p>整个 CART 算法会递归的生成子决策树，CART 算法中 <strong>所有的子决策树都是二叉树</strong> ，而其他算法比如 ID3 可以生成多叉树。</p>
<h3 id="pros.-and-cons."><span class="header-section-number">5.1.2</span> Pros. and Cons.</h3>
<ul>
<li>Cons:
<ul>
<li>决策树由于是非参数模型（Nonparametric model）对数据集做的假设很少（其他比如线性模型则要求数据满足线性分布），因此对应的模型参数很少，并且无需在训练之前进行假定，因此在训练时，参数很容易拟合向训练数据（对应的比如线性模型则由于参数需要 predetermined，因此通常参数的训练范围会有所限制，减小了过拟合的风险）。解决方式是 restrict the Decision Tree’s freedom during training，比如参数减小<code>max_depth</code>、<code>max_features</code>等<code>max_*</code>类参数，增大<code>min_samples_leaf</code>、<code>min_weight_fraction_leaf</code>等<code>min_*</code>类参数。除此之外，还有的解决方式是进行剪枝（依据 <span class="math inline">\(\chi^2\)</span> 检验）</li>
<li>对数据敏感，如果训练数据有微小的改动（比如坐标旋转 <span class="math inline">\(45^\circ\)</span>），都可能导致最终生成的决策树有很大的变化，进而导致过拟合。解决方式是使用 PCA 先处理数据。</li>
<li>算法是基于贪心策略建立，不能保证找到的是全局最优解。可以通过引入 Random Forest 算法解决。</li>
</ul></li>
<li>Pros:
<ul>
<li>前面分析过，计算速度较快</li>
<li>易于解释、容易使用、限制较小</li>
</ul></li>
</ul>
<h1 id="ensemble-learning-and-random-forests"><span class="header-section-number">6</span> Ensemble Learning and Random Forests</h1>
<blockquote>
<p>Wisdom of the crowd.</p>
</blockquote>
<p>黑魔法：</p>
<blockquote>
<p>You will often use Ensemble methods near the end of a project, once you have already built a few good predictors, to combine them into an even better predictor.</p>
</blockquote>
<h2 id="ensemble-时投票的方式"><span class="header-section-number">6.1</span> Ensemble 时投票的方式</h2>
<ul>
<li>hard voting: 哪一类得票多就属于哪一类</li>
<li>soft voting: 需要弱分类器可以预测概率，最终的结果是看所有的弱分类在每一类上的概率平均，哪一类值最大就属于哪一类</li>
</ul>
<h2 id="集成学习的理论基础"><span class="header-section-number">6.2</span> 集成学习的理论基础</h2>
<p>集成学习的理论基础主要基于大数定律。</p>
<hr />
<p><strong>大数定律：</strong> 在试验不变的条件下，重复试验多次，随机事件的频率近似等于它的概率。</p>
<hr />
<p>假设一个弱分类器就是一枚硬币，这种特殊的硬币头朝上的概率要大于头朝下的概率（头朝上51%，头朝下49%，也就是说弱分类器的准确率只有51%），但是随着试验量的增加，最终硬币头朝上的频率会趋向于它的概率51%，也就是这些次数中大部分的弱分类器都预测正确，结合 ensemble 的方式，最终分类结果正确。</p>
<p>但是，这个结果有一个很重要的前提：每次抛硬币时都是独立不相关的，也就是说弱分类器要尽量相互独立。但是在实际情况下通常很难保证，一种解决方式是在构造弱分类器时尽量使用不同的算法。</p>
<h2 id="bagging-and-pasting"><span class="header-section-number">6.3</span> Bagging and Pasting</h2>
<p>解决弱分类器尽量独立除了使用不同的弱分类器之外，还可以在弱分类器使用不同的样本子集。根据弱分类器采样样本时是放回抽样还是不放回抽样，分为了：</p>
<ul>
<li>Bagging: 放回抽样</li>
<li>Pasting：不放回抽样</li>
</ul>
<p>通常使用放回抽样，因为这样容易产生更多的子模型，不受样本容量的限制，而且在切分样本时，不容易收到随机切分的影响。</p>
<p>构造弱分类器后，可以通过 hard voting 的方式统计结果。从结构上来看，Bagging 或者 Pasting 天生适合并行。</p>
<h3 id="out-of-bagoob-evaluation"><span class="header-section-number">6.3.1</span> Out-of-Bag(oob) Evaluation</h3>
<p>Bagging 时，由于是放回抽样，因此可能会导致一部分样本从来不会抽到（大概占比 <span class="math inline">\(1-(1-\exp(-1)){\approx}37\%\)</span> ），因此很多时候在训练时，可以使用这部分数据作为验证集（scikit-learn 中<code>obb_score=True</code>）</p>
<h3 id="random-patches-and-random-subspaces"><span class="header-section-number">6.3.2</span> Random Patches and Random Subspaces</h3>
<p>同理采样样本，采样特征也可以增加弱分类器之间的独立性。同时采样样本和特征叫做 <em>Random Patches</em> method，只采样特征叫做 <em>Random Subspaces</em> method.</p>
<h3 id="random-forests"><span class="header-section-number">6.3.3</span> Random Forests</h3>
<p>随机森林是一种典型的 Bagging 算法，其使用决策树作为弱学习器，但是并非直接使用决策树，而是在决策树的基础上进行了一些改进：树中每个结点选择特征时，仅在一个随机子集中选择最优特征（传统的决策树是在所有的特征子集中进行选择）。更进一步的，在每个结点中，阈值的选择也是随机的，后者通常被称为 <em>Extra-Trees(Extremely Randomized Trees)</em> ，由于和 Random Forests 相比，Extra-Trees 少了一步寻找最优特征的操作，因此在计算速度上，Extra-Trees 计算得更快。</p>
<p>由于决策树的特性：重要的特征更可能出现在靠近根结点的位置，而相对不重要的特征更可能出现在靠近叶子结点的位置，因此随机森林能够很容易的得到每个特征的重要性，因此通常会在建模过程中用于大概的探索每个特征的重要性。</p>
<h2 id="boosting"><span class="header-section-number">6.4</span> Boosting</h2>
<blockquote>
<p>Train predictors sequentially, each trying to correct its predecessor.</p>
</blockquote>
<h3 id="adaboost"><span class="header-section-number">6.4.1</span> AdaBoost</h3>
<p>训练时，当前弱学习器会基于前一弱学习器的结果对样本进行权重调整（前一弱学习器分错的样本调高权重），所有的弱学习器都训练完成后，使用类似 Bagging 或 Pasting 的方式对各个弱学习器进行集成，集成时对效果相对较好的弱学习器分配较高的权重。从其结构可知，Boosting 无法并行。</p>
<hr />
<p><strong>AdaBoost 算法：</strong></p>
<ol type="1">
<li>将每个样本的初始权重设置为 <span class="math inline">\(\frac{1}{m}\)</span>，使用公式 <span class="math display">\[
r_j=\frac{\sum_{i=1,\hat{y}_j^{(i)}{\ne}y^{(i)}}^m{w_{(i)}}}{\sum_{i=1}^{m}w^{(i)}}
\]</span> 计算第 j 个弱学习器的错误率 <span class="math inline">\(r_j\)</span></li>
<li>使用公式 <span class="math display">\[
\alpha_j=\eta\log\frac{1-r_j}{r_j}
\]</span> 更新第 j 个弱学习器的权重</li>
<li>使用公式 <span class="math display">\[
w^{(i)}\gets
\begin{cases}
 w^{(i)},&amp; \text{if }\hat{y}_j^{(i)}=y^{(i)}\\
 w^{(i)}\exp(\alpha_j),&amp; \text{if }\hat{y}_j^{(i)}{\ne}y^{(i)}
\end{cases}
\]</span> 对所有的样本权重进行更新</li>
<li>当达到指定数量的弱学习器或达到指定的指标时算法停止。</li>
</ol>
<hr />
<h3 id="gradient-boosting"><span class="header-section-number">6.4.2</span> Gradient Boosting</h3>
<blockquote>
<p>Instead of tweaking the instance weights at every iteration like AdaBoost does, this method tries to fit the new predictor to the <em>residual errors</em> made by the previous predictor.</p>
</blockquote>
<p>以训练三个树作为示例：</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" title="1">tree_reg1 <span class="op">=</span> DecisionTreeRegressor(max_depth<span class="op">=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb2-2" title="2">tree_reg1.fit(X, y)</a>
<a class="sourceLine" id="cb2-3" title="3"></a>
<a class="sourceLine" id="cb2-4" title="4">y2 <span class="op">=</span> y<span class="op">-</span> tree_reg1.predict(X)</a>
<a class="sourceLine" id="cb2-5" title="5"></a>
<a class="sourceLine" id="cb2-6" title="6">tree_reg2 <span class="op">=</span> DecisionTreeRegressor(max_depth<span class="op">=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb2-7" title="7">tree_reg2.fit(X, y2)</a>
<a class="sourceLine" id="cb2-8" title="8"></a>
<a class="sourceLine" id="cb2-9" title="9">y3 <span class="op">=</span> y2 <span class="op">-</span> tree_reg2.predict(X)</a>
<a class="sourceLine" id="cb2-10" title="10"></a>
<a class="sourceLine" id="cb2-11" title="11">tree_reg3 <span class="op">=</span> DecisionTreeRegressor(max_depth<span class="op">=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb2-12" title="12">tree_reg3.fit(X, y3)</a></code></pre></div>
<p>最终预测结果为：</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" title="1">y_pred <span class="op">=</span> <span class="bu">sum</span>(tree.pred(X_new) <span class="cf">for</span> tree <span class="kw">in</span> (tree_reg1, tree_reg2, tree_reg3))</a></code></pre></div>
<h2 id="stacking"><span class="header-section-number">6.5</span> Stacking</h2>
<p>分为两步，首先切分数据集将一部分数据集用于训练出弱学习器，再基于另一部分数据集使用弱学习器的结果作为输入训练最终的学习器（Blender）</p>
<h1 id="dimensionality-reduction"><span class="header-section-number">7</span> Dimensionality Reduction</h1>
<p>在2维空间内，一个单元空间中（<span class="math inline">\(1{\times}1\)</span>），随机选择一个点，其离边界的距离小于0.001的概率只有<span class="math inline">\(0.4\%\)</span>。而在一个10,000维的空间中，这个概率却可以达到<span class="math inline">\(99.9999999\%\)</span>，因为在高维空间中，大多数点都非常靠近维度边界。同样，在2维空间中随机选择两个点，两者之间的平均距离大概是<span class="math inline">\(0.52\)</span>，3维空间中该值增加到<span class="math inline">\(0.66\)</span>，但是在一个1,000,000维的空间中，该值可以达到<span class="math inline">\(\sqrt{\frac{1,000,000}{6}}{\approx}408.25\)</span>。</p>
<p>这两个现象都暗示了在高维空间中，点大多数都是稀疏的（靠近边界），并且相互之间距离都较远。因此新样本极有可能和已有的训练样本都相距较远，这样导致最大的一个风险就是维度越高，过拟合的风险越大。</p>
<p>一个解决方式当然就是增加训练样本，但是研究表明训练样本需要的数量会随着维度的增加而指数增长，因此通常都会需要对高维的样本进行降维处理。</p>
<p>降维可以降低过拟合的风险、加快训练速度，有些时候还可以过滤掉一些无用的噪声，照理说应该所有的模型都直接使用降维才对。但是事情并非绝对，同压缩一样，降维肯定会损失一部分有效的信息，因此通常在考虑降维之前都会尝试使用原始数据进行一次训练看效果如何，如果出现速度较慢或者过拟合再考虑降维。基本思想还是高德纳的那句话：</p>
<blockquote>
<p>Don’t cut yourself.</p>
</blockquote>
<h2 id="常见的降维方式"><span class="header-section-number">7.1</span> 常见的降维方式</h2>
<p>简单说，有两种：</p>
<ol type="1">
<li>映射</li>
<li>manifold learning (流形学习？)</li>
</ol>
<p>第一种方式是通过将数据映射到一个低维的空间达到降维的目的；第二种方式是通过将高维空间中的平面展开至低维空间（“瑞士卷”展开）。</p>
<p>针对 Manifold Learning，原文的举例应该更直观一些：</p>
<blockquote>
<p>Think about the MNIST dataset: all handwritten digit images have some similarities. They are made of connected lines, the borders are white, they are more or less centered, and so on. If you randomly generated images, only a ridiculously tiny fraction of them would look like handwritten digits. In other words, the degrees of freedom available to you if you try to create a digit image are dramatically lower than the degrees of freedom you would have if you were allowed to generate any image you wanted. These constraints tend to squeeze the dataset into a lower-dimensional manifold.</p>
</blockquote>
<p>但是并非绝对，有时经过 manifold 之后的数据进行分类反而更加复杂一些。因此通常降维确实能够加快训练速度，但是其并非绝对的可以简化数据。</p>
<p>映射方式的典型代表是 PCA，manifold 方式的典型代表是 LLE。</p>
<h2 id="pca-主成分分析"><span class="header-section-number">7.2</span> PCA 主成分分析</h2>
<p>PCA 的原理是尽量选取保留了尽可能多的方差的坐标轴，然后将数据映射到这些坐标轴上。</p>
<blockquote>
<p>It seems reasonable to select the axis that preserves the maximum amount of variance, as it will most likely lose less information than the other projections.</p>
</blockquote>
<h3 id="主成分principal-component"><span class="header-section-number">7.2.1</span> 主成分（Principal Component）</h3>
<p>首先需要了解 PCA 的计算过程：</p>
<ol type="1">
<li>首先寻找一个保留了最大方差的坐标轴；</li>
<li>在第一个坐标轴的垂直方向寻找最大保留剩下方差的坐标轴；</li>
<li>在前两个坐标轴的基础上寻找最大保留了剩下方差的坐标轴；</li>
<li>如此往复，寻找出尽量多的坐标轴保留了原始数据的方差信息。</li>
</ol>
<p>在此过程中，每个坐标轴的单位向量就是一个_主成分_。</p>
<p>寻找这些保留了最大方差的坐标轴的方式通常是使用奇异值分解（Singular Value Decomposition, SVD），该操作会将原始的样本矩阵<span class="math inline">\(X\)</span>转换成点乘的形式：<span class="math inline">\(U\cdot\sum{\cdot}V^T\)</span>，其中<span class="math inline">\(V^T\)</span>就包含了我们所寻找的主成分。</p>
<p><strong>注意：</strong> 执行 PCA 之前需要保证数据已经 centered。不过 scikit-learn 默认会自动做该操作。</p>
<h3 id="映射"><span class="header-section-number">7.2.2</span> 映射</h3>
<p>在确定了主成分之后，可以选择前<span class="math inline">\(d\)</span>个保存了较多方差的主成分来对原始数据进行映射：</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" title="1">pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb4-2" title="2">X2D <span class="op">=</span> pca.fit_transform(X)</a></code></pre></div>
<p>映射之后可以通过<code>pca.explained_variance_ratio_</code>来查看所有<span class="math inline">\(d\)</span>个主成分分别保留的方差，其和就是<span class="math inline">\(d\)</span>个主成分保留了多少原始数据的方差。</p>
<p>但是通常<span class="math inline">\(d\)</span>是很难确定下来的，因此常用的做法是指定保留多少的方差：</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" title="1">pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="fl">0.95</span>)  <span class="co"># 保留95%的方差信息</span></a>
<a class="sourceLine" id="cb5-2" title="2">X_reduced <span class="op">=</span> pca.fit_transform(X)</a></code></pre></div>
<h3 id="压缩"><span class="header-section-number">7.2.3</span> 压缩</h3>
<p>通过 PCA 后，维度有所降低，那数据可以理解为已经进行了压缩，那执行 PCA 的反操作就可以理解为执行了解压缩，当然“解压缩”后肯定是无法回复称原来的数据集（毕竟损失了一部分方差信息），解压缩后的数据和原始数据之间的 mean squared distance 就叫做 <em>Reconstruction Error</em></p>
<h3 id="增量-pca"><span class="header-section-number">7.2.4</span> 增量 PCA</h3>
<p>和在线学习一样，如果存在内存大小限制问题，可以使用“增量”的方式：</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb6-1" title="1">inc_pca <span class="op">=</span> IncrementalPCA(n_components<span class="op">=</span><span class="dv">154</span>)</a>
<a class="sourceLine" id="cb6-2" title="2"><span class="cf">for</span> X_batch <span class="kw">in</span> np.array_split(X_mnist, <span class="dv">100</span>):</a>
<a class="sourceLine" id="cb6-3" title="3">    inc_pca.partial_fit(X_batch)</a>
<a class="sourceLine" id="cb6-4" title="4">X_mnist_reduced <span class="op">=</span> inc_pca.transform(X_mnist)</a></code></pre></div>
<h3 id="randomized-pca"><span class="header-section-number">7.2.5</span> Randomized PCA</h3>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb7-1" title="1">rnd_pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">154</span>, svd_solver<span class="op">=</span><span class="st">&#39;randomized&#39;</span>)</a>
<a class="sourceLine" id="cb7-2" title="2">X_reduced <span class="op">=</span> rnd_pca.fit_transform(X_mnist)</a></code></pre></div>
<p>传统的 PCA 的计算复杂度为<span class="math inline">\(O(m{\times}n^2)+O(n^3)\)</span>，随机 PCA 的计算复杂度可以降低到<span class="math inline">\(O(m{\times}d^2)+O(d^3)\)</span>，代价是该方式只能寻找到近似最优。</p>
<h2 id="kernel-pca"><span class="header-section-number">7.3</span> Kernel PCA</h2>
<p>在 SVM 中，核技巧可以将数据映射到高维空间，以使在低维空间线性不可分的问题转换为高维的线性可分问题。同样的思想应用到 PCA，产生了 kPCA 算法，通过使用非线形映射，将高维空间中数据映射到地位空间中，以达到降维的目的。典型的例子就是三维空间中的“瑞士卷”，可以通特定的 kPCA 算法对其进行展开，转换到二维平面。</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb8-1" title="1">rbf_pca <span class="op">=</span> KernelPCA(n_components<span class="op">=</span><span class="dv">2</span>, kernel<span class="op">=</span><span class="st">&#39;rbf&#39;</span>, gamma<span class="op">=</span><span class="fl">0.4</span>)</a>
<a class="sourceLine" id="cb8-2" title="2">X_reduced <span class="op">=</span> rbf_pca.fit_transform(X)</a></code></pre></div>
<p>由于 kPCA 是无监督的，因此并没有特别的指标进行选择合适的超参，通常的做法是结合特定的任务（比如分类）进行<code>GridSearchCV</code>来确定 kPCA 的超参。还有一种确定 kPCA 参数的方式是通过 Reconstruction Error 来确定。</p>
<h2 id="lle-locally-linear-embedding"><span class="header-section-number">7.4</span> LLE (Locally Linear Embedding)</h2>
<p>简单说来，该算法首先找出每个样本的 closest neighbors，然后到低维空间中找到近似对应关系的表达。因此这种方式尤其适合 unrolling twisted manifolds。</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb9-1" title="1">lle <span class="op">=</span> LocallyLinearEmbedding(n_components<span class="op">=</span><span class="dv">2</span>, n_neighbors<span class="op">=</span><span class="dv">10</span>)</a>
<a class="sourceLine" id="cb9-2" title="2">X_reduced <span class="op">=</span> lle.fit_transform(X)</a></code></pre></div>
<hr />
<p><strong>LLE 算法:</strong></p>
<ol type="1">
<li>对于每一个样本 <span class="math inline">\(x^{(i)}\)</span>，找到其<span class="math inline">\(k\)</span>个 closest neighbors；</li>
<li>将这<span class="math inline">\(k\)</span>个邻居样本传入线性函数来构造<span class="math inline">\(x^{(i)}\)</span>： <span class="math inline">\(x^{(i)&#39;}=\sum_{j=1}^mw_{i,j}x^{(j)}\)</span>，构造的目标是使的<span class="math inline">\(x^{(i)}\)</span>和 <span class="math inline">\(x^{(i)&#39;}\)</span> 之间的距离尽量的小；</li>
</ol>
<hr />
<p>公式化表达：</p>
<p><span class="math display">\[\hat{W}=\text{argmin}_W\sum_{i=1}^m||x^{(i)}-\sum_{j=1}^mw_{i,j}x^{(j)}||^2\]</span></p>
<p><span class="math display">\[
\text{subject to}
\begin{cases}
    w_{i,j}=0&amp; \text{if }x^{(j)}\text{ is not one of the k closest neighbors of  }x^{(i)}\\
    \sum_{j=1}^mw_{i,j} &amp; \text{for i=1,2,...,m}
\end{cases}
\]</span></p>
<p>其中 <span class="math inline">\(\hat{W}\)</span> 编码了样本中的所有样本的关系信息。下一步就是将样本映射到低维空间时，尽量的保存这些关系信息。</p>
</body>
</html>
